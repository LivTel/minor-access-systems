#!/bin/csh

# --------------------------------------
# Archive transfer script.
# --------------------------------------
#
# Usage: ari_xfer_rise n_threads [verbose]"
#   Compulsory parameter n_threads is maximum number of files to be simultaneously transfering"

#
# e.g.   ari_xfer 4               -- Send everything not already sent. Not output to STDOUT
# e.g.   ari_xfer 4 verbose       -- Send everything not already sent. Comments to STDOUT
#
# --------------------------------------
#

# Based on ari_archive_xfer_rt but with the SFX removed and replaced with scp.
# Other than that flow is identical

# GLS logging included
# JMM 12/2/09


# Define GLS binary location
set LTLOG = /usr/local/bin/ltlog_static


# This would not be required if we were running as occ
# DEPLOY_TMP is already in the environment
set DEPLOY_TMP = /occ/tmp

# Declare name of lock file.
set lock = ${DEPLOY_TMP}/ari_xfer.lock

# Define number of simultaneous transfers which are allowed.
set THREAD_COUNT = $1
set THREAD_LOCK=${DEPLOY_TMP}/xfer_thread_lock.

# Set the date format which will be use in logs
alias datestamp 'date +"%h %d %H:%M:%S"'
set procname = ari_xfer

# The archive.
set ARCHIVE_USER = data
#set ARCHIVE_HOST = 150.204.240.8
set ARCHIVE_HOST = lt-archive.astro.livjm.ac.uk
set ARCHIVE_PORT = 2222
set ARCHIVE_PATH = /data/archive/incoming/lt/

# Logfile and name of file containing list of transfered files
# Changed INFO to old filename for consistency with other scripts
# JMM 20080208
set LOGFILE = $DEPLOY_TMP/ari_xfer.log
set INFO    = $DEPLOY_TMP/ari_archive_xfer_list

# Where are the data (NFS mount).
set ARCHIVE_RATCAM_DIR = /mnt/rat-image
set ARCHIVE_SUPIRCAM_DIR = /mnt/supir-image
set ARCHIVE_RINGO_DIR = /mnt/grope-image
set ARCHIVE_MEABURN_DIR = /mnt/meaburn-image

# RJS. Mount points have moved since this was written. I have commented it out.
# RJS. Force mounting of rat-image if it is not already done.
#mount | grep rat-image
#if ( $status ) mount /mnt/rat-image
#mount | grep rat-image
#if ( $status ) mount /mnt/supir-image

set HOSTNAME = `printenv HOSTNAME`

set DEBUG = 0 

####################
# Parse command line
# This could be a lot more elegant!!!
####################
set nargs = ${#argv}
if ( $nargs == 2 ) then
  if ("$1" == "verbose") then
    set DEBUG = 1
  else 
    echo "Usage: ari_xfer n_threads [verbose]"
    echo "   Compulsory parameter n_threads is maximum number of files to be simultaneously transfering"

    exit 1
  endif 
endif

if ( $nargs > 2 ) then
  echo "Usage: ari_xfer n_threads [verbose]"
  echo "   Compulsory parameter n_threads is maximum number of files to be simultaneously transfering"

  exit 1
endif 

echo `datestamp` $HOSTNAME ${procname}: "Start xfer script " >> $LOGFILE
if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Start xfer script "


###########
# Lockfiles
###########
if ( -e $lock ) then
    ps -elf | grep ari_xfer | grep `cat $lock` > /dev/null
    if($? == 0) then
      if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "By running ps it looks like a transfer is underway. Transfer aborted."
      if ($DEBUG) xterm -hold -bg yellow -fg blue -title "XFER Lock Conflict" -e "cat /occ/tmp/xfer-locked.txt"
      exit 1
    else
      if ($DEBUG) echo "By running ps it looks like this is an out of date lock file. It has been deleted and transfer will proceed."
      rm $lock
    endif
endif

# Create lock file
echo $$ > $lock
chmod 777 $lock
if ($status != 0) then
    echo "** Error: Unable to create lockfile: $lock "
    exit 2
endif

# Now that the script's master lock file is established we can safely delete any 
# individual thread locks. They must be left over from another run.
set counter=0
while ($counter < $THREAD_COUNT)
  if (-e ${THREAD_LOCK}$counter) rm -f ${THREAD_LOCK}$counter
  @ counter++
end

# Now we have a lockfile created, we need to enfore cleanup at the end
onintr cleanup

##################
# End of Lockfiles
##################



# General housekeeping on the log files
if (! -e $LOGFILE) then
    touch $LOGFILE
endif
if (! -e $INFO) then
    touch $INFO
endif
# How many files in $INFO. This will be used at the end to deduce how many files were successfully transferred
set info_length_pre = `wc -l $INFO | awk '{print $1}'`




# Check GLS binary exists. If it doesn't, we set a flag and also notify something that we couldn't find it.
# However we still continue with the transfer; the GLS is secondary to getting the data across!
if ( ! -f $LTLOG ) then
    LTLOG_EXISTS=0
    echo `datestamp` $HOSTNAME ${procname}: "Cannot locate GLS CAPI binary: ${LTLOG}. Continuing with transfer anyway." >>& $LOGFILE
else
    LTLOG_EXISTS=1
endif
  


# Check number of files to xfer.
if (! -e ${ARCHIVE_RATCAM_DIR}) then
    echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_RATCAM_DIR}" >>& $LOGFILE
    if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_RATCAM_DIR}"
    exit 3
endif
if (! -e ${ARCHIVE_SUPIRCAM_DIR}) then
    echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_SUPIRCAM_DIR}" >>& $LOGFILE
    if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_SUPIRCAM_DIR}" 
    exit 4
endif
if (! -e ${ARCHIVE_RINGO_DIR}) then
    echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_RINGO_DIR}" >>& $LOGFILE
    if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_RINGO_DIR}"
    exit 5
endif
if (! -e ${ARCHIVE_MEABURN_DIR}) then
    echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_MEABURN_DIR}" >>& $LOGFILE
    if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Cannot locate archive image dir: ${ARCHIVE_MEABURN_DIR}"
    exit 6
endif

# First peruse all the directories to see what nights' data are getting sent. Normally this will just 
# be tonight, but no harm in checking for any left overs. The list of nights to consider gets written to ${DEPLOY_TMP}/transfer_datelist.
# For each night in the ${DEPLOY_TMP}/transfer_datelist, we count the number of raw frames and write the number into $DEPLOY_TMP/${date_to_count}.filecount.
# Lastly we actually send the $DEPLOY_TMP/${date_to_count}.filecount to archive so we can check we have everything.
if ($DEBUG) echo "Building list of all files to consider"
if ( -e ${DEPLOY_TMP}/transfer_datelist ) then
    /bin/rm ${DEPLOY_TMP}/transfer_datelist
endif
touch ${DEPLOY_TMP}/transfer_datelist
ls -1 ${ARCHIVE_RATCAM_DIR}/c_*_20??????_*_0.fits |& grep -v "No match" | cut -d"_" -f3 | sort | uniq >> ${DEPLOY_TMP}/transfer_datelist 
ls -1 ${ARCHIVE_SUPIRCAM_DIR}/s_*_20??????_*_0.fits |& grep -v "No match" | cut -d"_" -f3 | sort | uniq >> ${DEPLOY_TMP}/transfer_datelist 
ls -1 ${ARCHIVE_RINGO_DIR}/o_*_20??????_*_0.fits |& grep -v "No match" | cut -d"_" -f3 | sort | uniq >> ${DEPLOY_TMP}/transfer_datelist 
ls -1 ${ARCHIVE_MEABURN_DIR}/n_*_20??????_*_0.fits |& grep -v "No match" | cut -d"_" -f3 | sort | uniq >> ${DEPLOY_TMP}/transfer_datelist 

# added - jmm
if ($DEBUG) then 
  echo "Finished building list:"
  cat ${DEPLOY_TMP}/transfer_datelist
  echo "List ends."
endif

if($DEBUG) cat $DEPLOY_TMP/transfer_datelist
foreach date_to_count (`cat ${DEPLOY_TMP}/transfer_datelist`)
  set cf = `ls -1 ${ARCHIVE_RATCAM_DIR}/c_*_${date_to_count}_*_0.fits ${ARCHIVE_SUPIRCAM_DIR}/s_*_${date_to_count}_*_0.fits ${ARCHIVE_RINGO_DIR}/o_*_${date_to_count}*_0.fits ${ARCHIVE_MEABURN_DIR}/n_*_${date_to_count}_*_0.fits |& grep -v "No match" | wc -l `
  echo $cf > $DEPLOY_TMP/${date_to_count}.filecount 


  # scp command is the actual transfer
  if ($DEBUG) echo "Sending ${date_to_count}.filecount file"
  scp -P $ARCHIVE_PORT $DEPLOY_TMP/${date_to_count}.filecount ${ARCHIVE_USER}@${ARCHIVE_HOST}:${ARCHIVE_PATH}. >>& $LOGFILE
  if($DEBUG) cat $DEPLOY_TMP/${date_to_count}.filecount
  rm $DEPLOY_TMP/${date_to_count}.filecount
end

# Count up all the raw data ready to send
if ($DEBUG) echo "Building list of all files to consider again"
set cf = `ls -1 ${ARCHIVE_RATCAM_DIR}/c_*_20??????_*_0.fits ${ARCHIVE_SUPIRCAM_DIR}/s_*_20??????_*_0.fits ${ARCHIVE_RINGO_DIR}/o_*_20??????_*_0.fits ${ARCHIVE_MEABURN_DIR}/n_*_20??????_*_0.fits |& grep -v "No match" | wc -l`
set sz = `ls -l ${ARCHIVE_RATCAM_DIR}/c_*_20??????_*_0.fits ${ARCHIVE_SUPIRCAM_DIR}/s_*_20??????_*_0.fits ${ARCHIVE_RINGO_DIR}/o_*_20??????_*_0.fits ${ARCHIVE_MEABURN_DIR}/n_*_20??????_*_0.fits |& grep -v "No match" | awk '{count += $5} END { print (count/1000000)}'`

# We must bail out now if no files or else the foreach will "crash" the script. 
if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "There are $cf files to transfer with total size: $sz MBytes"
echo `datestamp` $HOSTNAME ${procname}: "There are $cf files to transfer with total size: $sz MBytes" >>& $LOGFILE
if ( $cf == 0 ) goto cleanup

# File transfers attempted 
set attempts = 0
# Files skipped
set sk = 0

#We want a sleep on the first time through the foreach loop. This
#gives the system time to close any half written files before the
#file transfer starts. It is only required on the first loop.
set first_run = 1

# Start of master loop which progressively cycles through all available files.
foreach file (${ARCHIVE_RATCAM_DIR}/c_?_20??????_*_0.fits ${ARCHIVE_SUPIRCAM_DIR}/s_*_20??????_*_0.fits ${ARCHIVE_RINGO_DIR}/o_*_20??????_*_0.fits ${ARCHIVE_MEABURN_DIR}/n_?_20??????_*_0.fits)

    if ($first_run == 1) then
      if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Sleeping on first loop."
      sleep 10
      set first_run = 0
    endif

    # The purge and transfer trip over each other pretty much every day. No real harm is done other than weird error
    # message because the file this script is trying to transfer no longer exists. It has been purged. The 
    # following jumps out of the loop if the file has disappeared.
    if (! -e $file ) then
      echo `datestamp` $HOSTNAME ${procname}: File $file no longer exists. Assuming it was just purged. >>& $LOGFILE
      if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: File $file no longer exists. Assuming it was just purged. 
      continue
    endif

    # Though we do not transfer reduced data, we use the existence of the reduced file to imply that the
    # exposure is complete and safe to transfer. Therefore I have to synthesize the reduced filename for
    # checking against.
    set root = `echo $file | cut -d"_" -f1-6`
    set pfile = ${root}_1.fits

#    set fs = `ls -s --block-size=1000000 $file | cut -d" " -f1 | awk '{print int($1)}'` 

    set toonew = 0

    #echo `datestamp` $HOSTNAME ${procname}: "Consider file $file " >>& $LOGFILE

# This script will will only transfer things that are either older than one hour
# or there is a reduced _1 file on disk. If anyone
# takes a single exposure of > 1 hour, it will get corrupted by the transfer, though the original
# file will be available in the site backups
        set now = `date +%s`
        set filetime = `date -r $file +%s`
        @ diff = $now - $filetime
        if (($diff < 3600) && (! -e $pfile)) then
          @ toonew++
        endif

	if ($toonew == 0) then
 
	  set find = `cat $INFO | grep $file `
	
	  if ($status == 0) then
	    if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Already transferred $file - skip"  
	    echo `datestamp` $HOSTNAME ${procname}: "Already transferred $file - skip"  >>& $LOGFILE
	    @ sk++
	  else


	    # At this point we have devided to send the file so copy it to the temp space
	    # zip it up and start the transfer

	    cp $file $DEPLOY_TMP/.
	    set erstat = $status
	    if ($erstat != 0) then
		echo "Failed to copy file $file from into DEPLOY_TMP : erstat = $erstat"
		echo `datestamp` $HOSTNAME ${procname}: "Failed to copy $file from into DEPLOY_TMP : erstat = $erstat" >> $LOGFILE
	    endif
	    set cfile = ${DEPLOY_TMP}/${file:t}

	    gzip -f $cfile
	    if ($status != 0) then
                echo "Failed to zippify $cfile : $status"
                echo `datestamp` $HOSTNAME ${procname}: "Failed to zippify $cfile : $status" >> $LOGFILE
            endif

	    set sfile = ${cfile}.gz
	    set dfile = ${ARCHIVE_PATH}${file:t}.gz
	    #echo `datestamp` $HOSTNAME ${procname}: "Will Send copy: $sfile to $dfile "  >>& $LOGFILE

	    # This block is the loop which checks the availability of transfer threads, waits until one
	    # is free and actually sends the file. The while() loop continuously cycles from from 0 -> $THREAD_COUNT
	    # attempting to create a lockfile. If is succeeds, an scp rtansfer is initiated. If it fails it tries the next.
	    #
	    # If something went wrong, this could technically be an infinite loop. In order to prevent that, a final time out
	    # could quite easily be implemented near the sleep command so that after a certain number of attempts we jump out
	    set counter=0
	    while ( $counter < $THREAD_COUNT)
	      lockfile -0 -r 0 ${THREAD_LOCK}$counter >& /dev/null
	      if ( $? == 0 ) then	# Lockfile was created, so start transfer
		set this_thread = $counter
		if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "Start transfer of $sfile on thread $this_thread" 
		echo `datestamp` $HOSTNAME ${procname}: "Start transfer of $sfile on thread $this_thread" >> $LOGFILE
		@ attempts ++
		# Following command does scp, some admin and deletes the lockfile. Whole thing is BG'd so that flow continues
		# while teh transfer is happening
		(nice scp -P $ARCHIVE_PORT $sfile ${ARCHIVE_USER}@${ARCHIVE_HOST}:${ARCHIVE_PATH}. >>& $LOGFILE ; set ex = $status ; echo `datestamp` $HOSTNAME ${procname}: "Exit status ($sfile) was: $ex" >>& $LOGFILE ; if ($ex == 0) echo $file >>& $INFO; /bin/rm -f $sfile; if ($ex != 0) echo `datestamp` $HOSTNAME ${procname}: "Transfer $file failed with status: $ex " >>& $LOGFILE; rm ${THREAD_LOCK}$this_thread >>& $LOGFILE & ) > /dev/null
		set counter = 99999	# Arbitrarily large number forces us to jump out of while() once a transfer has been initiated
	      else
	        @ counter++
	        if ($counter == $THREAD_COUNT) then
		  # If we have tried all threads, have a small sleep and then start again back at counter = 0
		  set counter = 0
		  sleep 1
		  echo `datestamp` $HOSTNAME ${procname}: "All $THREAD_COUNT threads are busy. $file waiting." >> $LOGFILE
	        endif
	      endif
	    end
	    # End of the transfer while() loop.


	  endif # End of  if ($status == 0) for test on whether this has already been sent
	
	else

	  if ($DEBUG) echo `datestamp` $HOSTNAME ${procname}: "File $file is < 1 hour old. Not transferring" 
	  echo `datestamp` $HOSTNAME ${procname}: "File $file is < 1 hour old. Not transferring" >>& $LOGFILE
	  @ sk++

        endif	# End of  if (toonew == 0)

   endif
end


#Ensure that all threads are complete before tidying up and writing out the stats
# All this does is open and close every lockfile in order. That can only be done once all tr5ansfers have finished.
set counter=0
while ( $counter < $THREAD_COUNT)
  lockfile ${THREAD_LOCK}$counter
  rm -f ${THREAD_LOCK}$counter
  @ counter++
end

set info_length_post = `wc -l $INFO | awk '{print $1}'`
@ ct = $info_length_post - $info_length_pre
@ ff = $attempts - $ct

echo `datestamp` $HOSTNAME ${procname}: "Run statistics" >>& $LOGFILE
echo `datestamp` $HOSTNAME ${procname}: "Total files: $cf " >>& $LOGFILE
echo `datestamp` $HOSTNAME ${procname}: "Files tranfers attempted this run: $attempts " >>& $LOGFILE
echo `datestamp` $HOSTNAME ${procname}: "Files skipped: $sk " >>& $LOGFILE
echo `datestamp` $HOSTNAME ${procname}: "Successful tranfers this run: $ct " >>& $LOGFILE
echo `datestamp` $HOSTNAME ${procname}: "Failed transfers: $ff ">>& $LOGFILE
#    echo "Total transfer $tt Mbytes" >>& $LOGFILE

echo `datestamp` $HOSTNAME ${procname}: "Transfer run completed successfully" >>& $LOGFILE

cleanup:
if (-e $lock) then
    /bin/rm -f $lock
    if ($status == 0) then
	if ($DEBUG) echo "Removed lockfile"
    else
	echo "** Warning: Unable to remove lockfile: $lock "
	echo `datestamp` $HOSTNAME ${procname}: "** Warning: Unable to remove lockfile: $lock " >> $LOGFILE
    endif
else
    echo "** Warning: Lockfile $lock was not found "
    echo `datestamp` $HOSTNAME ${procname}: "** Warning: Lockfile $lock was not found " >> $LOGFILE
endif
